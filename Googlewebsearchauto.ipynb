{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90828f62-2c0d-4aad-a882-d58fbd47f356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://freo.money/&sa=U&ved=2ahUKEwim68W_tfz_AhXbppUCHUU_C3EQFnoECAsQAg&usg=AOvVaw1x4NjQfXYW-Lz_bNnSnVCJ\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import bs4\n",
    "\n",
    "# Taking the city name as an input from the user\n",
    "city = \"Kolkata\"\n",
    "\n",
    "# Generating the URL\n",
    "url = \"https://google.com/search?q=freo\"\n",
    "\n",
    "# Sending HTTP request\n",
    "request_result = requests.get(url)\n",
    "\n",
    "# Parsing the HTML content\n",
    "soup = bs4.BeautifulSoup(request_result.text, \"html.parser\")\n",
    "\n",
    "# Finding the first search result link\n",
    "search_results = soup.find_all(\"a\")\n",
    "first_result_link = None\n",
    "\n",
    "for result in search_results:\n",
    "    link = result.get(\"href\")\n",
    "    if link.startswith(\"/url?q=\"):\n",
    "        first_result_link = link[7:]\n",
    "        break\n",
    "\n",
    "print(first_result_link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc0310cc-a371-4c70-9675-6851b08fcc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://freo.money/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import bs4\n",
    "\n",
    "# Taking the city name as an input from the user\n",
    "city = \"Kolkata\"\n",
    "\n",
    "# Generating the URL\n",
    "url = \"https://google.com/search?q=freo\"\n",
    "\n",
    "# Sending HTTP request\n",
    "request_result = requests.get(url)\n",
    "\n",
    "# Parsing the HTML content\n",
    "soup = bs4.BeautifulSoup(request_result.text, \"html.parser\")\n",
    "\n",
    "# Finding the first search result link\n",
    "search_results = soup.find_all(\"a\")\n",
    "first_result_link = None\n",
    "\n",
    "for result in search_results:\n",
    "    link = result.get(\"href\")\n",
    "    if link.startswith(\"/url?q=\"):\n",
    "        first_result_link = link[7:]\n",
    "        break\n",
    "\n",
    "# Extracting the smaller URL from the search result\n",
    "smaller_url = first_result_link.split(\"&sa\")[0]\n",
    "print(smaller_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b3cd879-2033-4d2c-b1cd-280743d38aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Query: Complaints to freo\n",
      "Smaller URL: https://freopay.com/customer-care-number/\n",
      "\n",
      "Search Query: Complaint to moneytap\n",
      "Smaller URL: https://www.mymoneymantra.com/moneytap-personal-loan-customer-care\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import bs4\n",
    "\n",
    "def get_smaller_urls(search_queries):\n",
    "    smaller_urls = []\n",
    "\n",
    "    for query in search_queries:\n",
    "        # Generating the URL\n",
    "        url = \"https://google.com/search?q=\" + query\n",
    "\n",
    "        # Sending HTTP request\n",
    "        request_result = requests.get(url)\n",
    "\n",
    "        # Parsing the HTML content\n",
    "        soup = bs4.BeautifulSoup(request_result.text, \"html.parser\")\n",
    "\n",
    "        # Finding the first search result link\n",
    "        search_results = soup.find_all(\"a\")\n",
    "        first_result_link = None\n",
    "\n",
    "        for result in search_results:\n",
    "            link = result.get(\"href\")\n",
    "            if link.startswith(\"/url?q=\"):\n",
    "                first_result_link = link[7:]\n",
    "                break\n",
    "\n",
    "        # Extracting the smaller URL from the search result\n",
    "        smaller_url = first_result_link.split(\"&sa\")[0]\n",
    "        smaller_urls.append(smaller_url)\n",
    "\n",
    "    return smaller_urls\n",
    "\n",
    "# Example usage\n",
    "search_queries = [\"Complaints to freo\",\"Complaint to moneytap\"]\n",
    "results = get_smaller_urls(search_queries)\n",
    "\n",
    "for query, result in zip(search_queries, results):\n",
    "    print(\"Search Query:\", query)\n",
    "    print(\"Smaller URL:\", result)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5de8a030-6541-4bca-bae4-d8d9d11ec62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import pandas as pd\n",
    "\n",
    "def get_smaller_urls(search_queries):\n",
    "    smaller_urls = []\n",
    "\n",
    "    for query in search_queries:\n",
    "        # Generating the URL\n",
    "        url = \"https://google.com/search?q=\" + query\n",
    "\n",
    "        # Sending HTTP request\n",
    "        request_result = requests.get(url)\n",
    "\n",
    "        # Parsing the HTML content\n",
    "        soup = bs4.BeautifulSoup(request_result.text, \"html.parser\")\n",
    "\n",
    "        # Finding the first search result link\n",
    "        search_results = soup.find_all(\"a\")\n",
    "        first_result_link = None\n",
    "\n",
    "        for result in search_results:\n",
    "            link = result.get(\"href\")\n",
    "            if link.startswith(\"/url?q=\"):\n",
    "                first_result_link = link[7:]\n",
    "                break\n",
    "\n",
    "        # Extracting the smaller URL from the search result\n",
    "        smaller_url = first_result_link.split(\"&sa\")[0]\n",
    "        smaller_urls.append(smaller_url)\n",
    "\n",
    "    return smaller_urls\n",
    "\n",
    "# Example usage\n",
    "search_queries = [\"Synderverse\"]\n",
    "results = get_smaller_urls(search_queries)\n",
    "\n",
    "# Create a DataFrame with search queries and smaller URLs\n",
    "df = pd.DataFrame({\"Search Query\": search_queries, \"Smaller URL\": results})\n",
    "\n",
    "# Save the DataFrame as an Excel file\n",
    "df.to_excel(\"C:/Users/DELL/Desktop/automation/webscraper automate/new/first_links.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39365cb9-b490-44b7-b759-6bd3589a511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import pandas as pd\n",
    "\n",
    "def get_smaller_urls(search_queries):\n",
    "    smaller_urls = []\n",
    "\n",
    "    for query in search_queries:\n",
    "        # Generating the URL\n",
    "        url = \"https://google.com/search?q=\" + query\n",
    "\n",
    "        # Sending HTTP request\n",
    "        request_result = requests.get(url)\n",
    "\n",
    "        # Parsing the HTML content\n",
    "        soup = bs4.BeautifulSoup(request_result.text, \"html.parser\")\n",
    "\n",
    "        # Finding the search result links\n",
    "        search_results = soup.find_all(\"a\")\n",
    "        result_links = []\n",
    "\n",
    "        for result in search_results:\n",
    "            link = result.get(\"href\")\n",
    "            if link.startswith(\"/url?q=\"):\n",
    "                smaller_url = link[7:].split(\"&sa\")[0]\n",
    "                result_links.append(smaller_url)\n",
    "\n",
    "        smaller_urls.extend(result_links)\n",
    "\n",
    "    return smaller_urls\n",
    "\n",
    "# Example usage\n",
    "search_queries = [\"flight prices to kolkata\"]\n",
    "results = get_smaller_urls(search_queries)\n",
    "\n",
    "# Create a DataFrame with search queries and smaller URLs\n",
    "df = pd.DataFrame({\"Search Query\": [query for query in search_queries for _ in range(len(results))],\n",
    "                   \"Smaller URL\": results})\n",
    "\n",
    "# Save the DataFrame as an Excel file\n",
    "df.to_excel(\"C:/Users/DELL/Desktop/automation/webscraper automate/new/first_page_links.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
